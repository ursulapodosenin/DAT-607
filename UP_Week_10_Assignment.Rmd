---
title: "UP_Week_10_Assignment"
author: "Ursula Podosenin"
date: "2024-03-29"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}

install.packages("tidytext", repos = "http://cran.us.r-project.org")
library("tidytext")

bing<- get_sentiments("bing")
```

```{r}

library(janeaustenr)
library(dplyr)
library(stringr)


# Processing books written by Jane Austen. It groups the text by book, assigns line numbers, ungroups the data, and then tokenizes the text into individual words using the tidytext package

ttidy_books_austen <- austen_books() |>
  group_by(book) |>
  mutate(
    linenumber = row_number()
  ) |>
  ungroup() |>
  tidytext::unnest_tokens(word, text)
```

```{r}

# Get joy sentiments from the bing lexicon
bing_joy <- get_sentiments("bing") |>
  filter(sentiment == "grief")

# Assuming 'tidy_books' is already defined
# Filter tidy_books for a specific book (e.g., "Sandition"), join with bing_joy sentiments, and count occurrences of each joy word
ttidy_books_austen |>
  filter(book == "Sandition") |>
  inner_join(bing_joy) |>
  count(word, sort = TRUE)
```

```{r}

library(tidyr)

jane_austen_sentiment <- ttidy_books_austen |>
  inner_join(get_sentiments("bing")) |>
  count(book, index = linenumber %/% 80, sentiment) |>
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) |>
  mutate(sentiment = positive - negative)
```

```{r}

library(ggplot2)

ggplot(jane_austen_sentiment, aes(index, sentiment, fill = book)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~book, ncol = 2, scales = "free_x")
```
```{r}

emma <- ttidy_books_austen |>
  filter(book == "Emma")

emma
```

```{r}

# Perform sentiment analysis using the Bing lexicon on "Pride and Prejudice"
emmabing <- emma |>
  inner_join(get_sentiments("bing")) |>
  mutate(method = "Bing")

# Combine sentiment analyses into one dataframe
combined_sentiments <-emmabing |>
  count(method, index = linenumber %/% 80, sentiment) |>
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) |>
  mutate(sentiment = positive - negative)
```
```{r}

# Combine sentiment analyses using Bing lexicon for "Pride and Prejudice"
bing_and_nrc <- bind_rows(
  # Sentiment analysis using the Bing lexicon
  emma |>
    inner_join(get_sentiments("bing")) |>
    mutate(method = "Bing")
) |>
  count(method, index = linenumber %/% 80, sentiment) |>
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) |>
  mutate(sentiment = positive - negative)


```

```{r}

bind_rows(bing_and_nrc) |>
  ggplot(aes(index, sentiment, fill = method)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~method, ncol = 1, scales = "free_y")
```

```{r}

bing_word_counts <- ttidy_books_austen |>
  inner_join(get_sentiments("bing")) |>
  count(word, sentiment, sort = TRUE) |>
  ungroup()
```

```{r}

# Create a tibble of custom words
custom_start_words <- tibble(
  word = c("start_word1", "start_word2"),  # Add your custom start words here
  lexicon = "custom"
)

# Combine custom start words with existing stop words
custom_stop_words <- bind_rows(custom_start_words, stop_words)

custom_stop_words
```

```{r}

install.packages("wordcloud", repos = "http://cran.us.r-project.org")
library("wordcloud")

ttidy_books_austen |>
  anti_join(stop_words) |>
  count(word) |>
  with(wordcloud(word, n, max.words = 50))
```

```{r}

install.packages("tm", repos = "http://cran.us.r-project.org")
library("tm")
library(wordcloud)


# Perform sentiment analysis using the Bing lexicon and count occurrences of each word
word_counts <- ttidy_books_austen |>
  inner_join(get_sentiments("bing")) |>
  count(word, sentiment, sort = TRUE)

# Reshape the data to create a matrix with words as rows and sentiments as columns
word_matrix <- xtabs(n ~ word + sentiment, data = word_counts)

# Generate a word cloud comparison
comparison.cloud(word_matrix, colors = c("blue", "green"), max.words = 100)
```

```{r}

# Filter Bing lexicon for negative sentiments
bing_negative <- get_sentiments("bing") |> 
  filter(sentiment == "negative")

# Count words per book and chapter
word_counts <- ttidy_books_austen |>
  group_by(book) |>
  summarize(words = n())

# Count negative words per book and chapter
negative_word_counts <- ttidy_books_austen |>
  semi_join(bing_negative) |>
  group_by(book) |>
  summarize(negativewords = n())
```

